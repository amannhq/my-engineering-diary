name: Weekly Review

on:
  schedule:
    - cron: '0 1 * * 0'   # 01:00 UTC every Sunday
  workflow_dispatch:

jobs:
  weekly-review:
    runs-on: ubuntu-latest
    env:
      PYTHONDONTWRITEBYTECODE: '1'
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}-${{ matrix.python-version || 'py311' }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Prefer repo requirements if present; otherwise install minimal runtime deps.
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            # Ensure a recent OpenAI package that includes the Responses API
            pip install "openai>=1.0.0" jsonschema
          fi

      - name: Validate goals file
        run: python -m ci.scripts.validate_goals

      - name: Check required secrets
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_ORG: ${{ secrets.OPENAI_ORG || '' }}
        run: |
          # Check for required secrets
          if [ -z "${OPENAI_API_KEY:-}" ]; then
            echo "::error::OPENAI_API_KEY secret is not set in repository secrets"
            exit 1
          fi
          
          # Log which optional secrets are available
          if [ -n "${OPENAI_ORG:-}" ]; then
            echo "OPENAI_ORG is set"
          else
            echo "OPENAI_ORG is not set (optional)"
          fi
          
          echo "All required secrets are present"

      - name: Generate weekly insight report
        id: weekly
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_ORG: ${{ secrets.OPENAI_ORG || '' }}
        run: |
          set -euo pipefail
          mkdir -p ci/daily-reports
          
          # Run the script and capture both stdout and stderr
          python -m ci.workflows.weekly_review --reports-dir ci/daily-reports --weekly-dir weekly-review > ci/daily-reports/weekly-output-raw.txt 2>&1 || true
          
          # Debug: Show the raw output
          echo "=== Raw output start ==="
          cat ci/daily-reports/weekly-output-raw.txt
          echo "=== Raw output end ==="
          
          # Try to extract valid JSON from the output
          if [ -s "ci/daily-reports/weekly-output-raw.txt" ]; then
            # Try to find a JSON object in the last 10 lines of output
            for line in $(tail -n 10 ci/daily-reports/weekly-output-raw.txt | tac); do
              if [[ "$line" == {* ]]; then
                echo "Found potential JSON in output, saving to weekly-output.json"
                echo "$line" > ci/daily-reports/weekly-output.json
                # Validate JSON
                if ! jq -e . ci/daily-reports/weekly-output.json >/dev/null 2>&1; then
                  echo "Warning: Extracted content is not valid JSON"
                  # Create a minimal valid JSON object if extraction failed
                  echo '{"error": "Failed to generate valid output"}' > ci/daily-reports/weekly-output.json
                fi
                break
              fi
            done
          fi
          
          # If we still don't have a valid JSON file, create one with an error
          if [ ! -f "ci/daily-reports/weekly-output.json" ] || ! jq -e . ci/daily-reports/weekly-output.json >/dev/null 2>&1; then
            echo '{"error": "Failed to generate weekly report"}' > ci/daily-reports/weekly-output.json
          fi
          
          # Show the final JSON for debugging
          echo "=== Final JSON output ==="
          cat ci/daily-reports/weekly-output.json
          echo ""

      - name: Summarize weekly checklist
        if: steps.weekly.outcome == 'success'
        run: |
          python - <<'PY'
          import json
          import os
          import re
          import sys
          from pathlib import Path
          from typing import Dict, Any
          
          def safe_load_json(file_path: Path) -> Dict[str, Any]:
              """Safely load JSON from a file with multiple fallback strategies."""
              try:
                  content = file_path.read_text(encoding="utf-8").strip()
                  if not content:
                      print("Error: Empty file")
                      return {"error": "Empty output file"}
                  
                  # Try direct JSON parse first
                  try:
                      return json.loads(content)
                  except json.JSONDecodeError as e:
                      print(f"Direct JSON parse failed: {e}")
                  
                  # Try to extract JSON object from content
                  json_match = re.search(r'\{(?:[^{}]|\{(?:[^{}]|\{[^{}]*\})*\})*\}', content)
                  if json_match:
                      try:
                          return json.loads(json_match.group(0))
                      except json.JSONDecodeError as e:
                          print(f"Extracted JSON parse failed: {e}")
                  
                  # If we get here, try to find the last line that looks like JSON
                  for line in reversed(content.splitlines()):
                      line = line.strip()
                      if line.startswith('{') and line.endswith('}'):
                          try:
                              return json.loads(line)
                          except json.JSONDecodeError:
                              continue
              
              except Exception as e:
                  print(f"Unexpected error loading JSON: {e}")
              
              # If all else fails, return an error object
              return {
                  "error": "Failed to parse output",
                  "file_content": content if 'content' in locals() else "<no content>"
              }
          
          output_path = Path("ci/daily-reports/weekly-output.json")
          data = safe_load_json(output_path)
          
          # Ensure we have the required fields with defaults
          data.setdefault("week_id", "unknown")
          data.setdefault("report_path", "")
          data.setdefault("checklist_path", "")
          data.setdefault("artifact_count", 0)
          data.setdefault("goal_progress_entries", 0)
          data.setdefault("partial_failures", 0)
          data.setdefault("partial_failures_detail", [])

          summary_lines = [
              f"# Weekly Review â€” {data.get('week_id', 'Unknown')}",
              "",
              f"- Report: {data.get('report_path', 'N/A')}",
              f"- Checklist: {data.get('checklist_path', 'N/A')}",
              f"- Daily artifacts processed: {data.get('artifact_count', 0)}",
              f"- Goal progress entries: {data.get('goal_progress_entries', 0)}",
              f"- Partial failures: {data.get('partial_failures', 0)}"
          ]

          partials = data.get("partial_failures_detail", [])
          if partials:
              summary_lines.extend(["", "## Partial failures detail"])
              for item in partials:
                  summary_lines.append(
                      f"- {item.get('log_ref', 'unknown')}: {', '.join(item.get('issues', []) or ['No details supplied'])}"
                  )

          step_summary = Path(os.environ["GITHUB_STEP_SUMMARY"])
          step_summary.write_text("\n".join(summary_lines) + "\n", encoding="utf-8")

          print("Checklist summary written to", step_summary)
          print(Path(data['checklist_path']).read_text(encoding="utf-8"))
          PY

      - name: Create or update weekly PR
        if: steps.weekly.outcome == 'success'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          # Ensure PR script is executable (so subprocess can call it)
          if [ -f ci/scripts/create_weekly_pr.sh ]; then
            chmod +x ci/scripts/create_weekly_pr.sh
          fi
          python - <<'PY'
          import json
          import subprocess
          from pathlib import Path

          output_path = Path("ci/daily-reports/weekly-output.json")
          data = json.loads(output_path.read_text(encoding="utf-8"))

          cmd = [
              "bash",
              "ci/scripts/create_weekly_pr.sh",
              "--week-id",
              data["week_id"],
              "--report-path",
              str(data["report_path"]),
              "--checklist-path",
              str(data["checklist_path"]),
              "--partial-failures",
              json.dumps(data.get("partial_failures_detail", [])),
          ]

          subprocess.run(cmd, check=True)
          PY

      - name: Upload weekly artifacts
        if: steps.weekly.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: weekly-review-${{ github.run_id }}
          path: |
            ci/daily-reports/
            weekly-review/
          retention-days: 21